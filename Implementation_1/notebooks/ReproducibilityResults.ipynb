{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "### Own modules\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "from PDE import Poisson1D\n",
    "from PINN import PINN\n",
    "from plotFunctions import plot_param_ntk_diff, plot_NTK_change, plot_convergence_rate\n",
    "\n",
    "### Set dtype and device to be used\n",
    "dtype = torch.float32\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Poisson\n",
    "\n",
    "\\begin{align}\n",
    "u_{xx} &= f(x), \\hspace{1.3cm} x \\in \\Omega \\\\\n",
    "u(x) &= g(x), \\hspace{1.3cm} x \\in \\partial \\Omega\n",
    "\\end{align}\n",
    "\n",
    "Where: \n",
    "\n",
    "\\begin{align}\n",
    "    f(x) &= -a^{2}\\pi^{2}\\sin(a\\pi x), \\hspace{0.2cm} x \\in [0,1] \\\\\n",
    "    g(x) &= 0, \\hspace{2.3cm} x = 0,1\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define exact, source and boundary condition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_u_exact(a,x):\n",
    "    \"\"\" \n",
    "    Exact solution\n",
    "    \"\"\"\n",
    "    u_exact = torch.sin(a*torch.pi*x)\n",
    "\n",
    "    return u_exact\n",
    "\n",
    "def f_x(a, x):\n",
    "    \"\"\"\n",
    "    Source/Forcing function\n",
    "    \"\"\"\n",
    "    fx = -(a**2)*(torch.pi**2)*torch.sin(a*torch.pi*x)\n",
    "       \n",
    "    return fx\n",
    "\n",
    "def g_x(x, xb):\n",
    "    \"\"\"\n",
    "    Boundary condition\n",
    "    \"\"\"\n",
    "    \n",
    "    ub = torch.zeros(x.size(), dtype=dtype)\n",
    "\n",
    "    xb1_idx = torch.where(x == xb[0])[0]\n",
    "    xb2_idx = torch.where(x == xb[1])[0]\n",
    "\n",
    "    ub[xb1_idx] = 0\n",
    "    ub[xb2_idx] = 0\n",
    "\n",
    "    return ub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PDE domain\n",
    "X_0,X_N = 0.,1.\n",
    "X_bc  = [X_0, X_N]\n",
    "\n",
    "# Number of points\n",
    "NX  = 100\n",
    "dx = (X_N - X_0) / NX\n",
    "\n",
    "# Create points for interior and boundary\n",
    "Xr = torch.linspace(X_0, X_N, NX, dtype=dtype, device=device, requires_grad=True).view(-1,1)\n",
    "Xb = torch.randint(0, 2, (NX,1),  dtype=dtype, device=device, requires_grad=True)\n",
    "X  = torch.hstack((Xr, Xb))\n",
    "\n",
    "### Setup PINN Network\n",
    "Br      = 100\n",
    "Bb      = 100\n",
    "rand_sampler = RandomSampler(X, replacement=True)\n",
    "XTrain       = DataLoader(X, batch_size=Br, shuffle=True)\n",
    "training_batches = len(XTrain.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup network training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net parameters\n",
    "input_size  = 1\n",
    "output_size = 1\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 1e-5\n",
    "epochs        = int(10e3)\n",
    "\n",
    "\n",
    "log_parameters = True\n",
    "log_NTK        = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup PDE Equation\n",
    "a   = [1, 2, 4]\n",
    "PDE = [Poisson1D(a_i) for a_i in a]\n",
    "\n",
    "# network neurons\n",
    "neurons     = [100]\n",
    "\n",
    "neural_nets =  [PINN(input_size, output_size, neurons, PDE_i, 'normal', dtype, device, log_parameters, log_NTK).to(device) for PDE_i in PDE]; \n",
    "\n",
    "for net_i in neural_nets:\n",
    "    net_i.eval()\n",
    "\n",
    "### Observe initial estimation of NTK Matrix\n",
    "X       = next(iter(XTrain))\n",
    "X_prime = next(iter(XTrain))\n",
    "\n",
    "xr       = X[:,0].to(device).view(-1,1);       xb       = X[:,1].to(device).view(-1,1)\n",
    "xr_prime = X_prime[:,0].to(device).view(-1,1); xb_prime = X_prime[:,1].to(device).view(-1,1)\n",
    "\n",
    "X = torch.stack([xr, xb], dim=0);              X_prime = torch.stack([xr_prime, xb_prime], dim=0)\n",
    "\n",
    "### PLOT Eigenvalue of NTK matrices\n",
    "fig, axs = plt.subplots(1,3, figsize=(23,6))\n",
    "ylabels = [r'$\\lambda_{K}$', r'$\\lambda_{uu}$', r'$\\lambda_{rr}$']\n",
    "\n",
    "for i in range(len(a)):\n",
    "\n",
    "    neural_nets[i].NTK(X, X_prime)\n",
    "\n",
    "    eig_K_plot    = np.sort(np.real(neural_nets[i].lambda_K.detach().cpu().numpy()))[::-1]\n",
    "    eig_K_uu_plot = np.sort(np.real(neural_nets[i].lambda_Kuu.detach().cpu().numpy()))[::-1]\n",
    "    eig_K_rr_plot = np.sort(np.real(neural_nets[i].lambda_Krr.detach().cpu().numpy()))[::-1]\n",
    "\n",
    "    axs[0].semilogx(eig_K_plot,      label=f'a={a[i]}');    axs[0].set_title('Eigenvalue of K')\n",
    "    axs[1].semilogx(eig_K_uu_plot,   label=f'a={a[i]}');    axs[1].set_title('Eigenvalue of {}'.format(r\"$K_{uu}$\"))\n",
    "    axs[2].semilogx(eig_K_rr_plot,   label=f'a={a[i]}');    axs[2].set_title('Eigenvalue of {}'.format(r\"$K_{rr}$\"))\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.legend()\n",
    "    # ax.ticklabel_format(axis='y', scilimits=(0,0))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(ylabels[i])\n",
    "    ax.set_xlabel(r'$Index$')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup PINN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "neurons = [[10], [100], [500]]\n",
    "a       = 4\n",
    "PDE     = Poisson1D(a)\n",
    "\n",
    "log_parameters  = True\n",
    "log_NTK         = True\n",
    "\n",
    "neural_nets  = [PINN(input_size, output_size, neurons_i, PDE, 'normal', dtype, device, log_parameters, log_NTK) for neurons_i in neurons]\n",
    "\n",
    "X       = next(iter(XTrain))\n",
    "X_prime = next(iter(XTrain))\n",
    "\n",
    "xr       = X[:,0].to(device).view(-1,1);       xb       = X[:,1].to(device).view(-1,1)\n",
    "xr_prime = X_prime[:,0].to(device).view(-1,1); xb_prime = X_prime[:,1].to(device).view(-1,1)\n",
    "\n",
    "x = torch.stack([xr, xb], dim=0);      x_prime = torch.stack([xr_prime, xb_prime], dim=0)\n",
    "\n",
    "\n",
    "for net in neural_nets:\n",
    "    net.to(device)\n",
    "    net.NTK(x, x_prime)\n",
    "    net.log_NTK(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.SGD\n",
    "# optimizer = optim.Adam\n",
    "\n",
    "optimizers = [optimizer(net_i.parameters(), learning_rate) for net_i in neural_nets]\n",
    "\n",
    "### NTK computation settings\n",
    "compute_NTK          = True\n",
    "compute_NTK_interval = 10\n",
    "\n",
    "### Adapation algorithm\n",
    "use_adaptation_algorithm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Train loop\n",
    "train_losses = []\n",
    "log_parameters = True\n",
    "\n",
    "# Auto Mixed Precision settings\n",
    "use_amp = True\n",
    "scaler  = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    epoch_loss   = 0.0\n",
    "\n",
    "    for i, x in enumerate(XTrain):\n",
    "\n",
    "        xr = x[:,0].view(-1,1).to(device); xb = x[:,1].view(-1,1).to(device)\n",
    "        \n",
    "        x  = torch.stack([xr, xb], dim=0)\n",
    "        if i == len(XTrain) - 1 and epoch % compute_NTK_interval != 0:\n",
    "            # get second data point set for NTK estimatino\n",
    "            x_prime  = x\n",
    "\n",
    "        for net, optimizer in zip(neural_nets, optimizers):\n",
    "\n",
    "            net.train()\n",
    "\n",
    "            if i == 0:\n",
    "                net.log_parameters(epoch)\n",
    "\n",
    "            # reset gradients  \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "\n",
    "                ### INTERIOR DOMAIN\n",
    "                # Predict interior points\n",
    "                u_hat_x   = net(xr)\n",
    "            \n",
    "                # determine gradients w.r.t interior points\n",
    "                U_x       =  net.compute_pde_gradient(u_hat_x, xr)\n",
    "\n",
    "                ### BOUNDARY DOMAIN\n",
    "                u_hat_xb    = net(xb)\n",
    "\n",
    "                # determine gradients w.r.t boundary points\n",
    "                U_xb       =  net.compute_pde_gradient(u_hat_xb, xb)\n",
    "                \n",
    "                # Compute forcing/source function\n",
    "                fx = f_x(a, xr).T.to(device)\n",
    "\n",
    "                # compute boundary condition\n",
    "                gx = g_x(xb, X_bc).T.to(device)\n",
    "\n",
    "                # Stack\n",
    "                U = torch.stack((U_x, U_xb), dim=0)\n",
    "\n",
    "                ## Backward step\n",
    "                net.backward(x, U, fx, gx, use_adaption=use_adaptation_algorithm)\n",
    "                epoch_loss += net.loss.item()\n",
    "\n",
    "            # Do optimisation step\n",
    "            if use_amp:\n",
    "                scaler.scale(net.loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                net.loss.backward()\n",
    "                optimizers.step()\n",
    "    ### END Batch loop\n",
    "\n",
    "    # Compute NTK\n",
    "    if epoch > 0:\n",
    "        if (epoch % compute_NTK_interval == 0 or epoch == epochs - 1) and compute_NTK:\n",
    "\n",
    "            for net in neural_nets:\n",
    "                net.eval()\n",
    "                net.NTK(x, x_prime)\n",
    "                if log_NTK:\n",
    "                    net.log_NTK(epoch)\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(XTrain))\n",
    "    \n",
    "    if epoch % 100 == 0 or epoch == epochs - 1: \n",
    "        print(f\"Epoch: {epoch:4d}     loss: {train_losses[-1]:5f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 1 - Parameter and ntk difference\n",
    "fig1, axs1 = plt.subplots(1,2, figsize=(18,6))\n",
    " \n",
    "for net in neural_nets:\n",
    "    fig1, axs1 = plot_param_ntk_diff(net, fig1, axs1)\n",
    "\n",
    "# FOR LARGEST WIDTH NETWORK  !!!@!\n",
    "net      = neural_nets[-1]\n",
    "\n",
    "# plot NTK matrix K change\n",
    "fig2, axs2 = plt.subplots(1,1)\n",
    "plot_NTK_change(net, fig2, axs2)\n",
    "\n",
    "# Plot convergence rate for all matrices\n",
    "fig3, axs3 = plt.subplots(1,1)\n",
    "plot_convergence_rate(net, fig3, axs3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
